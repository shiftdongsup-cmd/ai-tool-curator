import os
import requests
import json
from bs4 import BeautifulSoup
from google import genai

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")

def scrape_tools():
    # 1ìˆœìœ„ íƒ€ê²Ÿ: There's An AI For That (TAAFT) - êµ¬ì¡°ê°€ ë¹„êµì  ì•ˆì •ì 
    url = "https://theresanaiforthat.com/"
    # ë´‡ ì°¨ë‹¨ì„ í”¼í•˜ê¸° ìœ„í•œ ì‹¤ì œ ë¸Œë¼ìš°ì € ìœ„ì¥ í—¤ë”
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
        'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7'
    }
    
    try:
        print("There's An AI For That ìˆ˜ì§‘ ì‹œë„ ì¤‘...")
        res = requests.get(url, headers=headers, timeout=20)
        soup = BeautifulSoup(res.text, 'html.parser')
        tools = []

        # TAAFTì˜ ì‹ ê·œ ë„êµ¬ ë¦¬ìŠ¤íŠ¸ ì„¹ì…˜ (2026 êµ¬ì¡° ë°˜ì˜)
        items = soup.find_all('div', class_=lambda x: x and 'tool_card' in x.lower())[:10]
        
        if not items:
            # Futurepedia ì¬ì‹œë„ (ë” ë„“ì€ ë²”ìœ„ì˜ í´ë˜ìŠ¤ íƒìƒ‰)
            print("TAAFT ìˆ˜ì§‘ ì‹¤íŒ¨, Futurepediaë¡œ ì „í™˜...")
            url = "https://www.futurepedia.io/new"
            res = requests.get(url, headers=headers, timeout=20)
            soup = BeautifulSoup(res.text, 'html.parser')
            # 'card'ë‚˜ 'item' ë¬¸êµ¬ê°€ ë“¤ì–´ê°„ ëª¨ë“  div/a íƒœê·¸ ê²€ìƒ‰
            items = soup.find_all(['div', 'a'], class_=lambda x: x and ('card' in x.lower() or 'item' in x.lower()))[:12]

        for item in items:
            name = item.find(['h2', 'h3', 'div', 'span'], class_=lambda x: x and 'name' in x.lower())
            desc = item.find(['p', 'div', 'span'], class_=lambda x: x and ('desc' in x.lower() or 'text' in x.lower()))
            
            if name and desc:
                tools.append({"name": name.text.strip(), "description": desc.text.strip()})
        
        return tools
    except Exception as e:
        print(f"Scraping Error: {e}")
        return []

def filter_with_gemini(tool_list):
    client = genai.Client(api_key=GEMINI_API_KEY)
    # í˜ë¥´ì†Œë‚˜ ê°•í™” í”„ë¡¬í”„íŠ¸
    prompt = f"""
    ë„ˆëŠ” íŒŒì´ì¬ ê°œë°œìì´ì ë§ˆì¼€íŒ… ìë™í™” ì „ë¬¸ê°€ì¸ 'ì •ìˆ˜'ë‹˜ì˜ ê°œì¸ ë¹„ì„œì•¼.
    ì•„ë˜ ìˆ˜ì§‘ëœ AI íˆ´ ëª©ë¡ ì¤‘ ì—…ë¬´ íš¨ìœ¨ì„ ê·¹ëŒ€í™”í•  íˆ´ 3ê°œë¥¼ ì„ ì •í•´ì¤˜.
    [ë°ì´í„°] {json.dumps(tool_list, ensure_ascii=False)}
    
    [ë³´ê³  ì–‘ì‹]
    1. íˆ´ ì´ë¦„ ë° ë§í¬(ìœ ì¶” ê°€ëŠ¥í•  ê²½ìš°)
    2. ê°œë°œì/ë§ˆì¼€í„° ê´€ì ì—ì„œì˜ í•µì‹¬ í™œìš© í¬ì¸íŠ¸
    3. ê¸°ëŒ€ íš¨ê³¼ (í•œ ì¤„ ìš”ì•½)
    """
    response = client.models.generate_content(model="gemini-2.0-flash", contents=prompt)
    return response.text

def main():
    print("ğŸš€ íŒŒì´í”„ë¼ì¸ ê°€ë™...")
    raw_tools = scrape_tools()
    
    if not raw_tools:
        print("âŒ ëª¨ë“  ì‚¬ì´íŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‚¬ì´íŠ¸ì˜ ë³´ì•ˆ ì„¤ì •ì´ ê°•í™”ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return

    print(f"âœ… {len(raw_tools)}ê°œì˜ í›„ë³´ ë°œê²¬. AI í•„í„°ë§ ì¤‘...")
    summary = filter_with_gemini(raw_tools)
    
    requests.post(SLACK_WEBHOOK_URL, json={"text": summary})
    print("ğŸ“¬ ìŠ¬ë™ ë³´ê³  ì™„ë£Œ!")

if __name__ == "__main__":
    main()
